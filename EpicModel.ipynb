{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eHq8mgiZDWaB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "Output = ['depression','anxiety','bipolar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "W3GlBD3yDWaG"
   },
   "outputs": [],
   "source": [
    "#getting all the data\n",
    "dep = pd.read_csv('DS.csv')\n",
    "an = pd.read_csv('AS.csv')\n",
    "bi = pd.read_csv('BS.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xj01GEfnDWaJ"
   },
   "outputs": [],
   "source": [
    "dep = dep.rename(columns={'0': 'Polarity'})\n",
    "an = an.rename(columns={'0': 'Polarity'})\n",
    "bi = bi.rename(columns={'0': 'Polarity'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2hZTQOQ9DWaM"
   },
   "outputs": [],
   "source": [
    "dep = dep.drop('Unnamed: 0',axis=1 )\n",
    "an = an.drop('Unnamed: 0',axis=1   )  \n",
    "bi = bi.drop('Unnamed: 0',axis=1   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fFzdQg_cDWaQ",
    "outputId": "bac1aaed-f13c-47ca-8feb-2ba4005b70eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7873092182565145"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep.Polarity.mean(axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PZaylyzbDWaU",
    "outputId": "237b6633-8dcb-47aa-a28d-b4bea2427fd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7303806904008908"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "an.Polarity.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7VwHwX6eDWaX",
    "outputId": "44102790-db6e-47ec-a416-5bb380b30aa0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8271362007108509"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi.Polarity.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "HR5RwMVODWaa"
   },
   "outputs": [],
   "source": [
    "an.drop(an[an['Polarity'] > 0.95].index, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "57cEXuHbDWae",
    "outputId": "70370bd5-5bc1-49d4-9124-e0e210a195eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.702</td>\n",
       "      <td>12 Tips For Overcoming Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.702</td>\n",
       "      <td>12 Tips For Overcoming Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.658</td>\n",
       "      <td>Knowing Anxiety Attack Triggers | Anxiety Atta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.430</td>\n",
       "      <td>What does a panic attack feel like... to you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.638</td>\n",
       "      <td>Do I have anxiety?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122994</th>\n",
       "      <td>0.677</td>\n",
       "      <td>Worried about world ending/natural disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122996</th>\n",
       "      <td>0.697</td>\n",
       "      <td>Please exercise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122997</th>\n",
       "      <td>0.836</td>\n",
       "      <td>Anyone else not sure if they're actually sleep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122999</th>\n",
       "      <td>0.643</td>\n",
       "      <td>Why does it feel like an elephant is crushing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123000</th>\n",
       "      <td>0.668</td>\n",
       "      <td>Does anyone else feel like they just can't get...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96992 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Polarity                                                  1\n",
       "0          0.702                     12 Tips For Overcoming Anxiety\n",
       "1          0.702                     12 Tips For Overcoming Anxiety\n",
       "3          0.658  Knowing Anxiety Attack Triggers | Anxiety Atta...\n",
       "4          0.430      What does a panic attack feel like... to you?\n",
       "5          0.638                                 Do I have anxiety?\n",
       "...          ...                                                ...\n",
       "122994     0.677        Worried about world ending/natural disaster\n",
       "122996     0.697                                    Please exercise\n",
       "122997     0.836  Anyone else not sure if they're actually sleep...\n",
       "122999     0.643  Why does it feel like an elephant is crushing ...\n",
       "123000     0.668  Does anyone else feel like they just can't get...\n",
       "\n",
       "[96992 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "owtDTIGeDWah"
   },
   "outputs": [],
   "source": [
    "dep.drop(dep[dep['Polarity'] > 0.95].index, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "sQz71-m-DWak",
    "outputId": "e5ad23c7-734e-4306-aa7a-50e9e2c5e479"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6580</td>\n",
       "      <td>Was having a pretty awful day when a cute Indi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6360</td>\n",
       "      <td>I do a certain sport for 9 years yet am still ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7160</td>\n",
       "      <td>Kierkegaard said that depression is only dange...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8357</td>\n",
       "      <td>I care about you. All of you. No one deserves ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6730</td>\n",
       "      <td>I have had very bad depression for the past 8 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>0.7860</td>\n",
       "      <td>For the last month or two now I've just felt s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>0.6880</td>\n",
       "      <td>(17F) \\nIâm probably the most jealous, sad a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>0.6350</td>\n",
       "      <td>It would be such an easy way out, something th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>0.6940</td>\n",
       "      <td>I am a 19 year old..and my life is full of shi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120000</th>\n",
       "      <td>0.5840</td>\n",
       "      <td>I always feel like this especially when my dep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100535 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Polarity                                                  1\n",
       "0         0.6580  Was having a pretty awful day when a cute Indi...\n",
       "1         0.6360  I do a certain sport for 9 years yet am still ...\n",
       "2         0.7160  Kierkegaard said that depression is only dange...\n",
       "4         0.8357  I care about you. All of you. No one deserves ...\n",
       "5         0.6730  I have had very bad depression for the past 8 ...\n",
       "...          ...                                                ...\n",
       "119996    0.7860  For the last month or two now I've just felt s...\n",
       "119997    0.6880  (17F) \\nIâm probably the most jealous, sad a...\n",
       "119998    0.6350  It would be such an easy way out, something th...\n",
       "119999    0.6940  I am a 19 year old..and my life is full of shi...\n",
       "120000    0.5840  I always feel like this especially when my dep...\n",
       "\n",
       "[100535 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9bGouicEDWan"
   },
   "outputs": [],
   "source": [
    "bi.drop(bi[bi['Polarity'] > 0.95].index, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CpLVuHCODWap",
    "outputId": "479da1da-dfa0-47ce-b69a-82a856cc78d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8570</td>\n",
       "      <td>I'm trying to get this reddit going.  /r/depre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6020</td>\n",
       "      <td>This is a pair of questions that I think are i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8750</td>\n",
       "      <td>my brother came over today in tears. starting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6760</td>\n",
       "      <td>I'm pretty freaked out at the moment, my buddy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6666</td>\n",
       "      <td>I can't really see a better solution,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119569</th>\n",
       "      <td>0.8260</td>\n",
       "      <td>A few weeks ago I posted about getting the wro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119570</th>\n",
       "      <td>0.8640</td>\n",
       "      <td>I posted here a couple of weeks ago about havi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119571</th>\n",
       "      <td>0.8070</td>\n",
       "      <td>I want to bring awareness to \"virtual reality\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119572</th>\n",
       "      <td>0.8330</td>\n",
       "      <td>Sorry if this isn't the place for this kinda q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119574</th>\n",
       "      <td>0.9270</td>\n",
       "      <td>I notice that I feel the need again to constan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98004 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Polarity                                                  1\n",
       "0         0.8570  I'm trying to get this reddit going.  /r/depre...\n",
       "1         0.6020  This is a pair of questions that I think are i...\n",
       "2         0.8750  my brother came over today in tears. starting ...\n",
       "3         0.6760  I'm pretty freaked out at the moment, my buddy...\n",
       "4         0.6666              I can't really see a better solution,\n",
       "...          ...                                                ...\n",
       "119569    0.8260  A few weeks ago I posted about getting the wro...\n",
       "119570    0.8640  I posted here a couple of weeks ago about havi...\n",
       "119571    0.8070  I want to bring awareness to \"virtual reality\"...\n",
       "119572    0.8330  Sorry if this isn't the place for this kinda q...\n",
       "119574    0.9270  I notice that I feel the need again to constan...\n",
       "\n",
       "[98004 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "j7rg-4y1DWas"
   },
   "outputs": [],
   "source": [
    "for post in dep:\n",
    "    dep['Target'] = 0\n",
    "for post in an:\n",
    "    an['Target'] = 1\n",
    "for post in bi:\n",
    "    bi['Target'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "oWRguMDuDWav"
   },
   "outputs": [],
   "source": [
    "dep = dep.rename(columns={'1': 'Content'})\n",
    "an = an.rename(columns={'1': 'Content'})\n",
    "bi = bi.rename(columns={'1': 'Content'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "wcANhShFDWay",
    "outputId": "3dd27338-bff8-49d0-d99f-546f126ddfe2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\midhu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "stop = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = [word.lower() for word in text.split() if word.lower() not in stop]\n",
    "\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "kTepTLcCDWa1"
   },
   "outputs": [],
   "source": [
    "dep[\"Content\"] = dep[\"Content\"].map(remove_stopwords)\n",
    "an[\"Content\"] = an[\"Content\"].map(remove_stopwords)\n",
    "bi[\"Content\"] = bi[\"Content\"].map(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "JpDFmKo4DWa4"
   },
   "outputs": [],
   "source": [
    "data = pd.concat([dep, an,bi], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "F3HlZsdaDWa8",
    "outputId": "ee01f3ac-f158-4f37-9353-ff9f8e163c8a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Content</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6580</td>\n",
       "      <td>pretty awful day cute indian girl lab said loo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6360</td>\n",
       "      <td>certain sport 9 years yet still shit, obsessed...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7160</td>\n",
       "      <td>kierkegaard said depression dangerous coupled ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8357</td>\n",
       "      <td>care you. you. one deserves depression, one de...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6730</td>\n",
       "      <td>bad depression past 8 years, childhood, loneli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295526</th>\n",
       "      <td>0.8260</td>\n",
       "      <td>weeks ago posted getting wrong dose lamotrigin...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295527</th>\n",
       "      <td>0.8640</td>\n",
       "      <td>posted couple weeks ago start meds really real...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295528</th>\n",
       "      <td>0.8070</td>\n",
       "      <td>want bring awareness \"virtual reality\" rape mi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295529</th>\n",
       "      <td>0.8330</td>\n",
       "      <td>sorry place kinda question, know ask... took b...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295530</th>\n",
       "      <td>0.9270</td>\n",
       "      <td>notice feel need constantly meet everyone know...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295531 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Polarity                                            Content  Target\n",
       "0         0.6580  pretty awful day cute indian girl lab said loo...       0\n",
       "1         0.6360  certain sport 9 years yet still shit, obsessed...       0\n",
       "2         0.7160  kierkegaard said depression dangerous coupled ...       0\n",
       "3         0.8357  care you. you. one deserves depression, one de...       0\n",
       "4         0.6730  bad depression past 8 years, childhood, loneli...       0\n",
       "...          ...                                                ...     ...\n",
       "295526    0.8260  weeks ago posted getting wrong dose lamotrigin...       2\n",
       "295527    0.8640  posted couple weeks ago start meds really real...       2\n",
       "295528    0.8070  want bring awareness \"virtual reality\" rape mi...       2\n",
       "295529    0.8330  sorry place kinda question, know ask... took b...       2\n",
       "295530    0.9270  notice feel need constantly meet everyone know...       2\n",
       "\n",
       "[295531 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "KTZ5gkYdDWa-"
   },
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Count unique words\n",
    "def counter_word(text):\n",
    "    count = Counter()\n",
    "    for i in text.values:\n",
    "        for word in i.split():\n",
    "            count[word] += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "OoOdgKf9DWbB"
   },
   "outputs": [],
   "source": [
    "text = data.Content\n",
    "\n",
    "counter = counter_word(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "7TYotpI-DWbE",
    "outputId": "1a190643-7f10-4c20-d497-d08692aadac1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383006"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "HZKyA-9BDWbH"
   },
   "outputs": [],
   "source": [
    "num_words = len(counter)\n",
    "\n",
    "# Max number of words in a sequence\n",
    "max_length = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Kr7HnexnDWbJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "data = shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Sc8f3nvvDWbM"
   },
   "outputs": [],
   "source": [
    "data = data.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "m42wWXmuDWbP",
    "outputId": "e5cf969e-d937-4011-d25c-f3f805ccf35b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Content</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65651</td>\n",
       "      <td>0.7530</td>\n",
       "      <td>i'm 17 year old male, friends, lost two best f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80064</td>\n",
       "      <td>0.6540</td>\n",
       "      <td>havenât school week half, nothing sleep day ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38893</td>\n",
       "      <td>0.8270</td>\n",
       "      <td>first time week went gp start mental health ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72066</td>\n",
       "      <td>0.7120</td>\n",
       "      <td>people always say go professional help, everyt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>168689</td>\n",
       "      <td>0.5810</td>\n",
       "      <td>advice needed helping family member severe anx...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295526</th>\n",
       "      <td>280152</td>\n",
       "      <td>0.7250</td>\n",
       "      <td>\"on date\" reminders... clever posts made years...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295527</th>\n",
       "      <td>95003</td>\n",
       "      <td>0.8240</td>\n",
       "      <td>donât know start really except donât think...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295528</th>\n",
       "      <td>219401</td>\n",
       "      <td>0.8110</td>\n",
       "      <td>apparently getting lamotrigine turns drunk/inc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295529</th>\n",
       "      <td>283887</td>\n",
       "      <td>0.7930</td>\n",
       "      <td>diagnosed february psychotic episode. lot took...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295530</th>\n",
       "      <td>112983</td>\n",
       "      <td>0.5177</td>\n",
       "      <td>[help] become incredibly uncomfortable anxious...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295531 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  Polarity                                            Content  \\\n",
       "0        65651    0.7530  i'm 17 year old male, friends, lost two best f...   \n",
       "1        80064    0.6540  havenât school week half, nothing sleep day ...   \n",
       "2        38893    0.8270  first time week went gp start mental health ca...   \n",
       "3        72066    0.7120  people always say go professional help, everyt...   \n",
       "4       168689    0.5810  advice needed helping family member severe anx...   \n",
       "...        ...       ...                                                ...   \n",
       "295526  280152    0.7250  \"on date\" reminders... clever posts made years...   \n",
       "295527   95003    0.8240  donât know start really except donât think...   \n",
       "295528  219401    0.8110  apparently getting lamotrigine turns drunk/inc...   \n",
       "295529  283887    0.7930  diagnosed february psychotic episode. lot took...   \n",
       "295530  112983    0.5177  [help] become incredibly uncomfortable anxious...   \n",
       "\n",
       "        Target  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            1  \n",
       "...        ...  \n",
       "295526       2  \n",
       "295527       0  \n",
       "295528       2  \n",
       "295529       2  \n",
       "295530       1  \n",
       "\n",
       "[295531 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "szJLtHl_DWbT"
   },
   "outputs": [],
   "source": [
    "train_size = int(data.shape[0] * 0.8)\n",
    "\n",
    "train_sentences = data.Content[:train_size]\n",
    "train_labels = data.Target[:train_size]\n",
    "\n",
    "test_sentences = data.Content[train_size:]\n",
    "test_labels = data.Target[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "f1fGzv6gDWbV"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "W94wG8K5DWbX"
   },
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "CQf8VdHHDWba"
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "sUGLdHCbDWbc",
    "outputId": "d7ab65a6-e32b-461f-e8e5-c8826f2442cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104813"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "LqqcJzbNDWbf"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(\"word_index.pkl\",\"wb\")\n",
    "pickle.dump(word_index,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "OOEypKJ1DWbh"
   },
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "M5xZrZLJDWbk"
   },
   "outputs": [],
   "source": [
    "train_padded = keras.preprocessing.sequence.pad_sequences(\n",
    "    train_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "dhpIEJisDWbm"
   },
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "test_padded = keras.preprocessing.sequence.pad_sequences(\n",
    "    test_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "j1odojRbDWbp",
    "outputId": "efbcc58e-e9b2-4abc-c065-e9e7961bb6fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i'm 17 year old male, friends, lost two best friends ex broke february. job, depression, anxiety, introversion completely engulfed hate alive.i never felt depression brought damaging mindset \"it's real\". advice fed mum, nothing anger immense disgust caught cheating dad months back. never cared well being, mental heath issues dismissed etc. summer, bedroom day, messed sleeping cycle. friends. money. medication never went therapist life. feelings suicidal thoughts cloud everyday, eat less much days. august 29th either return final year levels (im uk), know quite honest. guy hates three classes, tried get ex etc good situation. also last 2 months school summer nobody, (oh make friends, find group) cant stress enough teenager particular school impossible year. everyone already knew years, simple. i'm writing this, knowing probably wont get reply anything need say somewhere silly 4.30 computer get out. &amp;#x200b; i'm lost i'm worrying returning school, etc? loved school got good results etc people makes hate life even more.\n",
      "[1, 1030, 47, 191, 1104, 32, 169, 103, 171, 32, 553, 418, 2223, 61, 19, 23, 10869, 246, 11515, 91, 617, 126, 27, 78, 19, 893, 4501, 2418, 1607, 242, 197, 2240, 1300, 71, 556, 4029, 4347, 1445, 2016, 280, 70, 29, 27, 1341, 74, 1249, 156, 12272, 260, 4057, 276, 614, 1995, 25, 1391, 424, 707, 32, 220, 157, 27, 112, 248, 11, 282, 231, 108, 2938, 433, 389, 314, 26, 67, 1781, 10311, 271, 1336, 1469, 47, 1416, 111, 2475, 4, 423, 850, 344, 1260, 378, 552, 133, 5, 553, 276, 37, 350, 49, 46, 94, 70, 60, 614, 488, 680, 40, 32, 102, 582, 361, 402, 140, 1800, 1547, 60, 957, 47, 109, 236, 377, 28, 1074, 1, 523, 56, 560, 202, 1263, 5, 1922, 34, 42, 83, 759, 2054, 253, 632, 1096, 5, 136, 213, 415, 1, 169, 1, 1426, 3085, 60, 276, 498, 60, 35, 37, 1477, 276, 13, 129, 91, 11, 12, 441]\n"
     ]
    }
   ],
   "source": [
    "print(data.Content[0])\n",
    "print(train_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "L0n4hKp8DWbr"
   },
   "outputs": [],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "-eozXub2DWbt"
   },
   "outputs": [],
   "source": [
    "def decode(text):\n",
    "    return \" \".join([reverse_word_index.get(i, \"?\") for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "fY4F4IfpDWbv",
    "outputId": "f405b081-8c91-4a57-bd06-19f54c4a75a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i'm 17 year old male friends lost two best friends ex broke february job depression anxiety introversion completely engulfed hate alive i never felt depression brought damaging mindset it's real advice fed mum nothing anger immense disgust caught cheating dad months back never cared well being mental heath issues dismissed etc summer bedroom day messed sleeping cycle friends money medication never went therapist life feelings suicidal thoughts cloud everyday eat less much days august 29th either return final year levels im uk know quite honest guy hates three classes tried get ex etc good situation also last 2 months school summer nobody oh make friends find group cant stress enough teenager particular school impossible year everyone already knew years simple i'm writing this knowing probably wont get reply anything need say somewhere silly 4 30 computer get out amp x200b i'm lost i'm worrying returning school etc loved school got good results etc people makes hate life even more\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(train_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "lUIGQc6_DWby",
    "outputId": "9d1c4dc4-ddcc-459e-962e-628a7a07f949"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train (236424, 60)\n",
      "Shape of test (59107, 60)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of train {train_padded.shape}\")\n",
    "print(f\"Shape of test {test_padded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "AwLASLsWDWb0"
   },
   "outputs": [],
   "source": [
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Embedding(num_words, 32, input_length=max_length))\n",
    "model.add(keras.layers.LSTM(64, dropout=0.1))\n",
    "model.add(keras.layers.Dense(16, activation=\"relu\")) \n",
    "model.add(keras.layers.Dense(3, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=3e-4)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "3wjSLkFlDWb3",
    "outputId": "0df7fbe7-f9b7-44ed-daeb-ce65bd68ea71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 60, 32)            12256192  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 12,282,115\n",
      "Trainable params: 12,282,115\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "YmDWQk5uDWb6",
    "outputId": "f6008da8-5219-4d83-def9-a7a21d9a1902"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1848/1848 [==============================] - 329s 178ms/step - loss: 0.4979 - accuracy: 0.7374 - val_loss: 0.3060 - val_accuracy: 0.8779\n",
      "Epoch 2/5\n",
      "1848/1848 [==============================] - 331s 179ms/step - loss: 0.2746 - accuracy: 0.8929 - val_loss: 0.2762 - val_accuracy: 0.8917\n",
      "Epoch 3/5\n",
      "1848/1848 [==============================] - 341s 184ms/step - loss: 0.2415 - accuracy: 0.9077 - val_loss: 0.2768 - val_accuracy: 0.8899\n",
      "Epoch 4/5\n",
      "1848/1848 [==============================] - 352s 191ms/step - loss: 0.2229 - accuracy: 0.9163 - val_loss: 0.2753 - val_accuracy: 0.8922\n",
      "Epoch 5/5\n",
      "1848/1848 [==============================] - 337s 182ms/step - loss: 0.2096 - accuracy: 0.9225 - val_loss: 0.2999 - val_accuracy: 0.8825\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_padded, train_labels,batch_size = 128, epochs=5, validation_data=(test_padded, test_labels),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VGV3XXSCDWb8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F7GhmMVbDWb_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "YterocxFDWcB",
    "outputId": "859e2b00-d986-4404-d8ff-4d820d0f2fdc"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-027473512554>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#getting all the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DS.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0man\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AS.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mbi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BS.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File DS.csv does not exist: 'DS.csv'"
     ]
    }
   ],
   "source": [
    "'''#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "Output = ['depression','anxiety','bipolar']\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "#getting all the data\n",
    "dep = pd.read_csv('DS.csv')\n",
    "an = pd.read_csv('AS.csv')\n",
    "bi = pd.read_csv('BS.csv')\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "dep = dep.rename(columns={'0': 'Polarity'})\n",
    "an = an.rename(columns={'0': 'Polarity'})\n",
    "bi = bi.rename(columns={'0': 'Polarity'})\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "dep = dep.drop('Unnamed: 0',axis=1 )\n",
    "an = an.drop('Unnamed: 0',axis=1   )  \n",
    "bi = bi.drop('Unnamed: 0',axis=1   )\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "dep.Polarity.mean(axis=0)\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "an.Polarity.mean(axis=0)\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "bi.Polarity.mean(axis=0)\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "an.drop(an[an['Polarity'] > 0.95].index, inplace = True) \n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "an\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "dep.drop(dep[dep['Polarity'] > 0.95].index, inplace = True) \n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "dep\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "bi.drop(bi[bi['Polarity'] > 0.95].index, inplace = True) \n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "bi\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "for post in dep:\n",
    "    dep['Target'] = 0\n",
    "for post in an:\n",
    "    an['Target'] = 1\n",
    "for post in bi:\n",
    "    bi['Target'] = 2\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "dep = dep.rename(columns={'1': 'Content'})\n",
    "an = an.rename(columns={'1': 'Content'})\n",
    "bi = bi.rename(columns={'1': 'Content'})\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "stop = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = [word.lower() for word in text.split() if word.lower() not in stop]\n",
    "\n",
    "    return \" \".join(text)\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "dep[\"Content\"] = dep[\"Content\"].map(remove_stopwords)\n",
    "an[\"Content\"] = an[\"Content\"].map(remove_stopwords)\n",
    "bi[\"Content\"] = bi[\"Content\"].map(remove_stopwords)\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "data = pd.concat([dep, an,bi], ignore_index=True)\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "data\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Count unique words\n",
    "def counter_word(text):\n",
    "    count = Counter()\n",
    "    for i in text.values:\n",
    "        for word in i.split():\n",
    "            count[word] += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "text = data.Content\n",
    "\n",
    "counter = counter_word(text)\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "len(counter)\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "num_words = len(counter)\n",
    "\n",
    "# Max number of words in a sequence\n",
    "max_length = 60\n",
    "\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "data = shuffle(data)\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "data = data.reset_index()\n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "\n",
    "data\n",
    "\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "\n",
    "train_size = int(data.shape[0] * 0.8)\n",
    "\n",
    "train_sentences = data.Content[:train_size]\n",
    "train_labels = data.Target[:train_size]\n",
    "\n",
    "test_sentences = data.Content[train_size:]\n",
    "test_labels = data.Target[train_size:]\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "\n",
    "import pickle\n",
    "f = open(\"word_index.pkl\",\"wb\")\n",
    "pickle.dump(word_index,f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "train_padded = keras.preprocessing.sequence.pad_sequences(\n",
    "    train_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\"\n",
    ")\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "test_padded = keras.preprocessing.sequence.pad_sequences(\n",
    "    test_sequences, maxlen=max_length, padding=\"post\", truncating=\"post\"\n",
    ")\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "print(data.Content[0])\n",
    "print(train_sequences[0])\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "\n",
    "def decode(text):\n",
    "    return \" \".join([reverse_word_index.get(i, \"?\") for i in text])\n",
    "\n",
    "\n",
    "# In[38]:\n",
    "\n",
    "\n",
    "decode(train_sequences[0])\n",
    "\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "\n",
    "print(f\"Shape of train {train_padded.shape}\")\n",
    "print(f\"Shape of test {test_padded.shape}\")\n",
    "\n",
    "\n",
    "# In[42]:\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "9O86pkifDWcE"
   },
   "outputs": [],
   "source": [
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Embedding(num_words, 32, input_length=max_length))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "# Conv1D + global max pooling\n",
    "model.add(keras.layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3))\n",
    "model.add(keras.layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model.add(keras.layers.LSTM(64, dropout=0.1))\n",
    "model.add(keras.layers.Dense(128, activation=\"relu\")) \n",
    "model.add(keras.layers.Dense(3, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=3e-4)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "HWKW0KJgDWcI",
    "outputId": "9e3e57bb-ceea-4866-95ac-3ee46ad86a5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 60, 32)            12256192  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 60, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 18, 128)           28800     \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 4, 128)            114816    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 12,416,707\n",
      "Trainable params: 12,416,707\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "9PqW_3-FDWcK",
    "outputId": "065718d3-4933-4405-85fb-e8540e651bab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1848/1848 [==============================] - 287s 155ms/step - loss: 0.4419 - accuracy: 0.7811 - val_loss: 0.2904 - val_accuracy: 0.8845\n",
      "Epoch 2/5\n",
      "1848/1848 [==============================] - 296s 160ms/step - loss: 0.2810 - accuracy: 0.8875 - val_loss: 0.2778 - val_accuracy: 0.8894\n",
      "Epoch 3/5\n",
      "1848/1848 [==============================] - 293s 159ms/step - loss: 0.2562 - accuracy: 0.8992 - val_loss: 0.2670 - val_accuracy: 0.8938\n",
      "Epoch 4/5\n",
      "1848/1848 [==============================] - 313s 169ms/step - loss: 0.2400 - accuracy: 0.9065 - val_loss: 0.2768 - val_accuracy: 0.8902\n",
      "Epoch 5/5\n",
      "1848/1848 [==============================] - 293s 158ms/step - loss: 0.2268 - accuracy: 0.9124 - val_loss: 0.2830 - val_accuracy: 0.8884\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_padded, train_labels,batch_size = 128, epochs=5, validation_data=(test_padded, test_labels),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "PxBSVorsDWcO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\midhu\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: epicmodel2\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"epicmodel2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "w9m7qsvoDWcQ"
   },
   "outputs": [],
   "source": [
    "model.save(\"epicmodel2\", save_format = \"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ipYdslqeDWcT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "EpicModel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
